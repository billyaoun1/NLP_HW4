{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5Yox0gG1DsF"
   },
   "source": [
    "Homework 4: Neural Language Models  (& ðŸŽƒ SpOoKy ðŸ‘» authors ðŸ§Ÿ data) - Task 4, Option A\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names\n",
    "----\n",
    "Names: __William Aoun__ (Write these in every notebook you submit.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Compare your generated sentences (25 points)\n",
    "----\n",
    "\n",
    "In this task, you'll analyze one of the models that you produced in Task 3. You'll need to compare against the corresponding file that we have provided for you that was generated from the vanilla n-gram language model.\n",
    "\n",
    "Choose *__one__* of option A (this notebook) or B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxWlOU9k1DsQ"
   },
   "source": [
    "\n",
    "\n",
    "Option A: Evaluate the generated words of *character*-based models\n",
    "---\n",
    "\n",
    "Your job for this option is to programmatically measure two things for character-based models where n = 3, 4 and 5 (you will need to do some extra training of your character-based model to produce these; put cells with the code you use to generate these files at the end of your Task 3 notebook):\n",
    "\n",
    "- the percentage of words produced by each model (neural and vanilla) that are valid english words.\n",
    "- the percentage of words produced by each model (neural and vanilla) that are valid english words *and* were not seen at train time.\n",
    "\n",
    "For this task, you'll first need to define what you consider a \"word\" so you know how to evaluate your output. Take into account how you will deal with punctuation!\n",
    "\n",
    "Make sure to turn in any necessary supporting files along with your submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12a. What is your definition of a word for this task? __Any string of letters in between non letter characters. All words are converted to lowercase to compare with the dictionary and evaluate whether the model produces valid words.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English dictionary loaded: 234377 words\n"
     ]
    }
   ],
   "source": [
    "# your imports here\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "\n",
    "nltk.download(\"words\", quiet=True)\n",
    "english_words = {word.lower() for word in words.words()}\n",
    "print(f\"English dictionary loaded: {len(english_words)} words\")\n",
    "\n",
    "\n",
    "def extract_words(text: str) -> list[str]:\n",
    "    return re.findall(r\"[a-zA-Z]+\", text.lower())\n",
    "\n",
    "df = pd.read_csv(\"spooky_author_train.csv\")\n",
    "training_words = set()\n",
    "for text in df[\"text\"]:\n",
    "    training_words.update(extract_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here! (add as many cells as you'd like)\n",
    "\n",
    "\n",
    "def evaluate_model(file: str, model: str, n: int) -> dict:\n",
    "    with open(file, \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    words = extract_words(text)\n",
    "    valid = [w for w in words if w in english_words]\n",
    "    invalid = [w for w in words if w not in english_words]\n",
    "    valid_unseen = [w for w in valid if w not in training_words]\n",
    "\n",
    "    total = len(words)\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"n\": n,\n",
    "        \"valid\": valid,\n",
    "        \"invalid\": invalid,\n",
    "        \"pct_valid\": len(valid) / total * 100,\n",
    "        \"pct_valid_unseen\": len(valid_unseen) / total * 100,\n",
    "    }\n",
    "\n",
    "\n",
    "results = [\n",
    "    evaluate_model(\"generated_charbased.txt\", \"neural\", 3),\n",
    "    evaluate_model(\"generated_charbased_4.txt\", \"neural\", 4),\n",
    "    evaluate_model(\"generated_charbased_5.txt\", \"neural\", 5),\n",
    "    evaluate_model(\"spooky_vanilla_3_char.txt\", \"vanilla\", 3),\n",
    "    evaluate_model(\"spooky_vanilla_4_char.txt\", \"vanilla\", 4),\n",
    "    evaluate_model(\"spooky_vanilla_5_char.txt\", \"vanilla\", 5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = []\n",
    "invalid_data = []\n",
    "\n",
    "for r in results:\n",
    "    for word in r[\"valid\"]:\n",
    "        valid_data.append({\"model\": r[\"model\"], \"n\": r[\"n\"], \"sequence\": word})\n",
    "    for word in r[\"invalid\"]:\n",
    "        invalid_data.append({\"model\": r[\"model\"], \"n\": r[\"n\"], \"sequence\": word})\n",
    "\n",
    "pd.DataFrame(valid_data).to_csv(\"valid_words_lms.csv\", index=False)\n",
    "pd.DataFrame(invalid_data).to_csv(\"invalid_words_lms.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural_n4: ['strance', 'strance', 'strance', 'strance', 'strance', 'strance', 'strance', 'strance', 'strance', 'strance']\n",
      "neural_n5: ['sall', 'sall', 'sall', 'sall', 'sall', 'sall', 'sall', 'sall', 'sall', 'sall']\n",
      "vanilla_n3: ['aboultiethe', 'whild', 'uption', 'lon', 'angs', 'sichand', 'thathe', 'hou', 'juppred', 'inincesto']\n",
      "vanilla_n4: ['beams', 'imps', 'franginaluse', 'writy', 'thods', 'ter', 'wharation', 'desperface', 'stration', 'circleave']\n",
      "vanilla_n5: ['providention', 'breated', 'probes', 'betterns', 'll', 'throneousness', 'littleman', 'frant', 'proportrayer', 'withought']\n"
     ]
    }
   ],
   "source": [
    "for r in results:\n",
    "    if r[\"invalid\"]:\n",
    "        sample = random.sample(r[\"invalid\"], min(50, len(r[\"invalid\"])))\n",
    "        print(f\"{r['model']}_n{r['n']}: {sample[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| model   | n | % valid | % valid unseen | % should be valid |\n",
      "|---------|---|---------|----------------|-------------------|\n",
      "| neural  | 3 |   100.0 |            0.0 |               0.0 |\n",
      "| neural  | 4 |    72.7 |            0.0 |               0.0 |\n",
      "| neural  | 5 |    58.3 |            0.0 |               0.0 |\n",
      "| vanilla | 3 |    51.0 |            7.9 |               5.0 |\n",
      "| vanilla | 4 |    65.9 |            3.8 |               8.0 |\n",
      "| vanilla | 5 |    79.3 |            2.1 |              12.0 |\n"
     ]
    }
   ],
   "source": [
    "manual_counts = {\n",
    "    \"neural_n3\": 0,\n",
    "    \"neural_n4\": 0,\n",
    "    \"neural_n5\": 0,\n",
    "    \"vanilla_n3\": 5,\n",
    "    \"vanilla_n4\": 8,\n",
    "    \"vanilla_n5\": 12,\n",
    "}\n",
    "\n",
    "print(\"| model   | n | % valid | % valid unseen | % should be valid |\")\n",
    "print(\"|---------|---|---------|----------------|-------------------|\")\n",
    "for r in results:\n",
    "    key = f\"{r['model']}_n{r['n']}\"\n",
    "    manual = manual_counts[key]\n",
    "    print(\n",
    "        f\"| {r['model']:7} | {r['n']} | {r['pct_valid']:7.1f} | {r['pct_valid_unseen']:14.1f} | {manual:17.1f} |\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13a.\n",
    "For each value of n = 3, 4, and 5:\n",
    "- the percentage of words produced by each model (neural and vanilla) that are valid english words\n",
    "- the percentage of words produced by each model (neural and vanilla) that are valid english words *and* were not seen at train time\n",
    "- Gather the sequences of characters that are determined not to be words for each model. Randomly sample 50 of these sequences, and count how many of them *should have* been counted as words in your opinion.\n",
    "\n",
    "Fill in this table with your answers:\n",
    "| model | n | \\% valid | \\% valid and not-seen at train | \\% not valid that should have been |\n",
    "| - | - | - | - | - |\n",
    "| neural | 3 | 100 | 0 | 0 |\n",
    "| vanilla | 3 | 51 | 7.9 | 5 |\n",
    "| neural | 4 | 72.7 | 0 | 0 |\n",
    "| vanilla | 4 | 65.9 | 3.8 | 8 |\n",
    "| neural | 5 | 58.3 | 0 | 0 |\n",
    "| vanilla | 5 | 79.3 | 2.1 | 12 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit two csv files alongside this notebook: `valid_words_lms.csv` and `invalid_words_lms.csv`. Both files should have __three__ columns: `model`, `n`, `sequence`. `model` will have the value `neural` or `vanilla`. `n` will be the n-gram level. `sequence` will be the corresponding sequence of characters. `valid_words_lms.csv` should contain all sequences from both models you determined to be valid words. `invalid_words_lms.csv` will have all sequences from both models you programatically determined to be invalid words."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "wordembeddings_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (myenv311)",
   "language": "python",
   "name": "myenv311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05041e657fa0436a83611a3d2d345b99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3cd0685004814c0d974a1d809e0e2b4f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b0dca775977048f38841afae3d906eb6",
      "value": "100%"
     }
    },
    "140057e9712f46af9ebf5825ef9b1390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_05041e657fa0436a83611a3d2d345b99",
       "IPY_MODEL_a818afa6bb4f43c8b7e32a3c04f17211",
       "IPY_MODEL_72a47718e310461fbd61b312f7bf7cfe"
      ],
      "layout": "IPY_MODEL_488b55855d4d4ffc8af6d3d77aa3fdf8"
     }
    },
    "150adc7de7f54d63a215482e6a977067": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b93060412f54083b6dd7b9203ae55d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cd0685004814c0d974a1d809e0e2b4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "488b55855d4d4ffc8af6d3d77aa3fdf8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72a47718e310461fbd61b312f7bf7cfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4d9e5b3a1e144e6b34a55ab5cbce43f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_150adc7de7f54d63a215482e6a977067",
      "value": " 19579/19579 [00:00&lt;00:00, 18295.70it/s]"
     }
    },
    "843343b9adc84d949f839d51814d55aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a4d9e5b3a1e144e6b34a55ab5cbce43f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a818afa6bb4f43c8b7e32a3c04f17211": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b93060412f54083b6dd7b9203ae55d0",
      "max": 19579,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_843343b9adc84d949f839d51814d55aa",
      "value": 19579
     }
    },
    "b0dca775977048f38841afae3d906eb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
